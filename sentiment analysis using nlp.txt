import nltk.classify.util
from nltk.classify import NaiveBayesClassifier
from nltk.corpus import movie_reviews

Step 2: Define a function to extract features:

def extract_features(word_list):
return dict([(word, True) for word in word_list])

Step 3: We need training data for this, so we will use movie reviews in NLTK:

if __name__=='__main__':
   # Load positive and negative reviews  
   positive_fileids = movie_reviews.fileids('pos')
   negative_fileids = movie_reviews.fileids('neg')

Step 4: Let’s separate these into positive and negative reviews:

features_positive = [(extract_features(movie_reviews.words(fileids=[f])), 
           'Positive') for f in positive_fileids]
   features_negative = [(extract_features(movie_reviews.words(fileids=[f])), 
           'Negative') for f in negative_fileids]

Step 5: Divide the data into training and testing datasets:

# Split the data into train and test (80/20)
   threshold_factor = 0.8
   threshold_positive = int(threshold_factor * len(features_positive))
   threshold_negative = int(threshold_factor * len(features_negative))

Step 6: Extract the features:

features_train = features_positive[:threshold_positive] + features_negative[:threshold_negative]
   features_test = features_positive[threshold_positive:] + features_negative[threshold_negative:]  
   print "\nNumber of training datapoints:", len(features_train)
   print "Number of test datapoints:", len(features_test)

Step 7: We will use a Naive Bayes classifier. Define the object and train it:

# Train a Naive Bayes classifier
   classifier = NaiveBayesClassifier.train(features_train)
   print "\nAccuracy of the classifier:", nltk.classify.util.accuracy(classifier, features_test)

Step 8: The classifier object contains the most informative words that it obtained during analysis. These words basically have a strong say in what’s classified as a positive or a negative review. Let’s print them out:

print "\nTop 10 most informative words:"
   for item in classifier.most_informative_features()[:10]:
       print item[0]

Step 9: Create a couple of random input sentences:

# Sample input reviews

   input_reviews = [
       "It is an amazing movie", 
       "This is a dull movie. I would never recommend it to anyone.",
       "The cinematography is pretty great in this movie", 
       "The direction was terrible and the story was all over the place" 
   ]

Step 10: Run the classifier on those input sentences and obtain the predictions:

print "\nPredictions:"
   for review in input_reviews:
       print "\nReview:", review
       probdist = classifier.prob_classify(extract_features(review.split()))
       pred_sentiment = probdist.max()

Step 11: Print the output:

print "Predicted sentiment:", pred_sentiment 
       print "Probability:", round(probdist.prob(pred_sentiment), 2)
